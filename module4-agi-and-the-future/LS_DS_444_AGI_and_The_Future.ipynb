{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IizNKWLomoA"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 4 Lesson 4*\n",
    "\n",
    "# General Artificial Intelligence and the Future\n",
    "*aka your last class*\n",
    "\n",
    "![Future City](https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/City-of-the-future.jpg/640px-City-of-the-future.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "moj-4gr89pum"
   },
   "source": [
    "# Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EZdBzC6pvV9"
   },
   "source": [
    "## Defining Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9Y6I1aO9uCz"
   },
   "source": [
    "A straightforward definition of Artificial Intelligence would simply be \"intelligence, created from technology rather than biology.\" But that simply raises the question - what is *intelligence*?\n",
    "\n",
    "In the early history of computers, this seemed like an easier question. Intelligence meant solving tricky problems - things that took time and mental effort for a human to figure out.\n",
    "\n",
    "Defined that way, computers have made a litany of intelligent achievements over the years:\n",
    "- Arithmetic\n",
    "- Logic\n",
    "- Chess\n",
    "- Go\n",
    "- StarCraft\n",
    "- Mathematical proofs\n",
    "- Understanding natural language\n",
    "- Generating natural language\n",
    "- Understanding images\n",
    "- Generating images\n",
    "- Making medical diagnoses\n",
    "- Fitting and *optimizing* ML models\n",
    "\n",
    "And many more - every time you fit a simple regression, you're facilitating an act of artificial intelligence. You're writing code that will (hopefully) understand and generalize based on data, giving a \"human-like\" ability to intuit and predict something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXdC1uCC91ID"
   },
   "source": [
    "## \"General\" Intelligence - a moving target\n",
    "\n",
    "But, somehow, that isn't what most people *really* mean when they talk about AI.\n",
    "\n",
    "![And they both react poorly to showers.](https://imgs.xkcd.com/comics/ai.png)\n",
    "\n",
    "Somewhere that word \"general\" snuck in, and now we're concerned about \"Artificial General Intelligence.\" So, what is that?\n",
    "\n",
    "![Data](https://upload.wikimedia.org/wikipedia/en/0/09/DataTNG.jpg)\n",
    "\n",
    "The inspiration is likely characters such as the above, but that's not a definition. Intuitively the claim is \"computers that can be thrown in a variety of environments and learn without guidance\", but another good definition (based on how people use the term) may simply be \"whatever we haven't figured out how to get computers to do yet.\"\n",
    "\n",
    "Repeatedly, claims are made about tasks that will require a \"true AI\" to achieve. Then, when those tasks are completed, the bar is moved, and \"true AI\" is somehow always a bit further off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJV_2Ozk5LLV"
   },
   "source": [
    "## AI - Hype versus Value\n",
    "\n",
    "Hot off the presses! [Google launches an end-to-end AI platform](https://techcrunch.com/2019/04/10/google-expands-its-ai-services/)!\n",
    "\n",
    "...\n",
    "\n",
    "What does that mean? Well, it might mean a lot, but it's a little unclear what. Some selected [Hacker News](https://news.ycombinator.com/item?id=19626275) comments:\n",
    "\n",
    "> This platform focuses not on the this-AI-is-magic-and-can-solve-everything like many AI SaaS startups announced on Hacker News, but focuses on how to actually integrate this AI into production workflows, which is something I wish was discussed more often in AI. -- minimaxir\n",
    "\n",
    "> Looks like Google is taking over Cloud (from AWS) for AI by building an ecosystem and building tools for non Data scientists - consumer level product. Surely IBM can do similar thing with their recent Redhat acquisition, but will they ? -- amrrs\n",
    "\n",
    "> I work in building and deploying production ML/AI models but I'm having a lot of trouble cutting through the marketing jargon in this article and on Google's website as well. Can someone explain what this does in engineering terms? How does this differ from something like AWS Sagemaker? -- chibg10\n",
    "\n",
    "> This will make a bunch of startup's life really hard. I think it makes it harder to justify investing in your own ML pipeline or even building your own models for many use cases. -- petard\n",
    "\n",
    "One thing it definitely means - AI is a hot keyword, and people making hiring and other corporate decisions will be on the look out for it, even if they're not sure what it is.\n",
    "\n",
    "So - yes, you *do* know AI. AI is a real thing, and you are capable of using \"artificial\" technology to bring about real *intelligence* and insight.\n",
    "\n",
    "Do you know how to make an intelligent anthropomorphic android? No - and nobody else does yet, either. And that's OK. There's still lots of cool advances and things to learn and build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpSkJFuIkJeU"
   },
   "source": [
    "## Automation, for good and ill\n",
    "\n",
    "It is worth spending a moment considering the double-edged sword that is automation. This story did not begin with artificial intelligence, or even statistics or mathematics - it began when the first tool inventor figured out how to make something clever like a lever or a wheel, and use it to reduce the amount of labor needed to achieve some task.\n",
    "\n",
    "In the modern day we talk about automation, but in practice most technology is best considered as a *productivity multiplier* - all businesses still need at least *some* humans around, if nothing else to make policy decisions and collect profit. But the productivity of each individual person can be greatly enhanced through the use of technology.\n",
    "\n",
    "Consider farming - formerly a signification source of employment (and also small family owned farms), technology has tranformed it into a large scale industry where a handful of people produce as much as many more did before. This progression has happened in many areas - fortunately, it is usually accompanied by job growth and opportunity as new markets and services are created by technology as well.\n",
    "\n",
    "So, is it different now? Maybe - \"history will say\" is the only safe stance. But we are automating work at an accelerating rate, and it's unclear where all this growth is going and where the opportunities will be. There's a pretty good bet that it'll involve computers and data - and that's probably a large part of why you're here!\n",
    "\n",
    "The purpose of this section is not to convince you of anything - it is just to make you think. As a Data Scientist, you will have an outsized impact on society, and it is your responsibility to consider that impact and what you want to do with it.\n",
    "\n",
    "**Important caveat** - think and engage with society, *but* strive to not be strident or unduly certain when you do so. Broadcasting political beliefs, especially while on the job market, usually closes more doors than it opens. So, consider perspectives, and encourage dialogue - don't just (re)broadcast outrage at the latest injustice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vXHDbNnzGZz"
   },
   "source": [
    "## AutoML - taking our own jobs\n",
    "\n",
    "Us Data Scientists are not immune to automation. Behold, yet another voyage with the RMS Titanic ðŸš¢:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YN4O5Ikxy2g8"
   },
   "source": [
    "![AutoML applied to Titanic data](https://github.com/minimaxir/automl-gs/raw/master/docs/console-demo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iy6RIQn9zKhp"
   },
   "source": [
    "### Using AutoML on some data you've probably seen before\n",
    "\n",
    "Let's start with [automl-gs](https://github.com/minimaxir/automl-gs), a very new library that just works directly from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "colab_type": "code",
    "id": "GkJUFfsgnqr_",
    "outputId": "cf810bae-5195-4e9b-e157-1ef9a10f1b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting automl_gs\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/51/27833a08fe4f83711b09836ddd9128e275a6900c47e0e5782112ed611484/automl_gs-0.2.1.tar.gz\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from automl_gs) (0.24.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from automl_gs) (0.20.3)\n",
      "Collecting autopep8 (from automl_gs)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/f3/24b437da561b6af4840c871fbbda32889ca304fc1f7b6cc3ada8b09f394a/autopep8-1.4.4.tar.gz (114kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 33.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from automl_gs) (4.32.2)\n",
      "Requirement already satisfied: jinja2>=2.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from automl_gs) (2.10)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from automl_gs) (3.12)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->automl_gs) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->automl_gs) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->automl_gs) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn->automl_gs) (1.1.0)\n",
      "Requirement already satisfied: pycodestyle>=2.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from autopep8->automl_gs) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jinja2>=2.8->automl_gs) (1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->automl_gs) (1.11.0)\n",
      "Building wheels for collected packages: automl-gs, autopep8\n",
      "  Running setup.py bdist_wheel for automl-gs ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/2d/5e/f0/deffbd0fcc4afd6b065366dded7b9c8cd1b7c02f6b39c24552\n",
      "  Running setup.py bdist_wheel for autopep8 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/7e/f5/4b/c19e6276126325eb8071b273347c05a830c37a82b9b3b81510\n",
      "Successfully built automl-gs autopep8\n",
      "Installing collected packages: autopep8, automl-gs\n",
      "Successfully installed automl-gs-0.2.1 autopep8-1.4.4\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install automl_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "QsGIh584kH3A",
    "outputId": "247ecbf6-6958-43dd-81d4-00c985be5e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-27 16:26:46--  https://github.com/ryanleeallred/datasets/raw/master/car_regression.csv\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/ryanleeallred/datasets/master/car_regression.csv [following]\n",
      "--2019-07-27 16:26:46--  https://raw.githubusercontent.com/ryanleeallred/datasets/master/car_regression.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.248.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.248.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 263167 (257K) [text/plain]\n",
      "Saving to: â€˜car_regression.csvâ€™\n",
      "\n",
      "car_regression.csv  100%[===================>] 257.00K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2019-07-27 16:26:46 (33.1 MB/s) - â€˜car_regression.csvâ€™ saved [263167/263167]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/ryanleeallred/datasets/raw/master/car_regression.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "mR0ba-7ikJCd",
    "outputId": "ff858080-368f-4a42-cfe6-ffbd31385880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make,price,body,mileage,engV,engType,registration,year,drive\n",
      "23,15500.0,0,68,2.5,1,1,2010,1\n",
      "50,20500.0,3,173,1.8,1,1,2011,2\n",
      "50,35000.0,2,135,5.5,3,1,2008,2\n",
      "50,17800.0,5,162,1.8,0,1,2012,0\n",
      "55,16600.0,0,83,2.0,3,1,2013,1\n",
      "30,6500.0,3,199,2.0,3,1,2003,0\n",
      "59,10500.0,4,185,1.5,0,1,2011,0\n",
      "50,21500.0,3,146,1.8,1,1,2012,2\n",
      "50,22700.0,3,125,2.2,0,1,2010,2\n"
     ]
    }
   ],
   "source": [
    "!head car_regression.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "colab_type": "code",
    "id": "JwEChFqKkLdW",
    "outputId": "4c7af1af-20ca-4c46-afff-1154da461671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving a regression problem, minimizing mse using tensorflow.\n",
      "\n",
      "Modeling with field specifications:\n",
      "make: numeric\n",
      "body: categorical\n",
      "mileage: numeric\n",
      "engV: numeric\n",
      "engType: categorical\n",
      "registration: categorical\n",
      "year: numeric\n",
      "drive: categorical\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0e8dc9426740c18f23dc9eb69da602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836ae192aa224cc7ba66c4f32ae0f1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bf47de8a1866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoml_gs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautoml_grid_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mautoml_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'car_regression.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/automl_gs/automl_gs.py\u001b[0m in \u001b[0;36mautoml_grid_search\u001b[0;34m(csv_path, target_field, target_metric, framework, model_name, context, num_trials, split, num_epochs, col_types, gpu, tpu_address)\u001b[0m\n\u001b[1;32m     92\u001b[0m                     header=(best_result is None))\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# If the target metric improves, save the new hps/files,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from automl_gs import automl_grid_search\n",
    "\n",
    "automl_grid_search('car_regression.csv', 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NSTNAnT9dS6J"
   },
   "source": [
    "Uh oh, what happened? There is an [open issue](https://github.com/minimaxir/automl-gs/issues/14) which suggests running via the command line `automl_gs` tool rather than the Python module to get better error messages for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1146
    },
    "colab_type": "code",
    "id": "svF0TnE0keaj",
    "outputId": "33dbd241-31a1-4b09-f5c7-adf7bbc7b6f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving a regression problem, minimizing mse using tensorflow.\n",
      "\n",
      "Modeling with field specifications:\n",
      "make: numeric\n",
      "body: categorical\n",
      "mileage: numeric\n",
      "engV: numeric\n",
      "engType: categorical\n",
      "registration: categorical\n",
      "year: numeric\n",
      "drive: categorical\n",
      "  0%|                                                | 0/100 [00:00<?, ?trial/s]\n",
      "  0%|                                                 | 0/20 [00:00<?, ?epoch/s]\u001b[ATraceback (most recent call last):\n",
      "  File \"model.py\", line 48, in <module>\n",
      "    model_train(df, encoders, args, model)\n",
      "  File \"/home/ec2-user/SageMaker/DS-Unit-4-Sprint-3-Deep-Learning/module4-agi-and-the-future/automl_train/pipeline.py\", line 409, in model_train\n",
      "    batch_size=256)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 776, in fit\n",
      "    shuffle=shuffle)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2382, in _standardize_user_data\n",
      "    exception_prefix='input')\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 362, in standardize_input_data\n",
      "    ' but got array with shape ' + str(data_shape))\n",
      "ValueError: Error when checking input: expected input_engtype to have shape (1,) but got array with shape (2,)\n",
      "\n",
      "  0%|                                                 | 0/20 [00:00<?, ?epoch/s]\u001b[ATraceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/bin/automl_gs\", line 11, in <module>\n",
      "    sys.exit(cmd())\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/automl_gs/automl_gs.py\", line 175, in cmd\n",
      "    tpu_address=args.tpu_address)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/automl_gs/automl_gs.py\", line 94, in automl_grid_search\n",
      "    train_results = results.tail(1).to_dict('records')[0]\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!automl_gs car_regression.csv price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRqYSY4yde1L"
   },
   "source": [
    "So, the real issue is in some intermediary step - let's see if we can get rid of engType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1505
    },
    "colab_type": "code",
    "id": "N0sHkyabk9Pj",
    "outputId": "26a91983-c1b8-4003-cfd4-6978516828fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving a regression problem, minimizing mse using tensorflow.\n",
      "\n",
      "Modeling with field specifications:\n",
      "make: numeric\n",
      "body: categorical\n",
      "mileage: numeric\n",
      "engV: numeric\n",
      "engType: ignore\n",
      "registration: categorical\n",
      "year: numeric\n",
      "drive: categorical\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac4afa8fcdf4e95945d88ac865ffeb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d0e2b0ac1a4141890d2480444ee00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1a57aaf11428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m automl_grid_search('car_regression.csv', 'price', col_types={\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'engType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m })\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/automl_gs/automl_gs.py\u001b[0m in \u001b[0;36mautoml_grid_search\u001b[0;34m(csv_path, target_field, target_metric, framework, model_name, context, num_trials, split, num_epochs, col_types, gpu, tpu_address)\u001b[0m\n\u001b[1;32m     92\u001b[0m                     header=(best_result is None))\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# If the target metric improves, save the new hps/files,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "automl_grid_search('car_regression.csv', 'price', col_types={\n",
    "    'engType': 'ignore'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9y2xI5ShN4n"
   },
   "source": [
    "It gets further, but is perhaps a bit too bleeding edge for us. Let's try [TPOT](https://github.com/EpistasisLab/tpot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "xltSPWmMhQod",
    "outputId": "78745223-eb42-41bb-8275-da36697e656a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/4e/9ce813120662d9bd357aac6cb922f4b08b85049ed86eb47fe34a02d27f14/TPOT-0.10.2-py3-none-any.whl (75kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 24.8MB/s \n",
      "\u001b[?25hCollecting joblib>=0.10.3 (from tpot)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 286kB 31.0MB/s \n",
      "\u001b[?25hCollecting stopit>=1.1.1 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
      "Collecting update-checker>=0.16 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.12.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tpot) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tpot) (1.1.0)\n",
      "Requirement already satisfied: pandas>=0.20.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tpot) (0.24.2)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tpot) (4.32.2)\n",
      "Collecting deap>=1.0 (from tpot)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/00/3c8c234a84b5e969ee7278da0dd451388fe58891a7828a1516d3c2001934/deap-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (151kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153kB 37.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.18.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tpot) (0.20.3)\n",
      "Requirement already satisfied: requests>=2.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from update-checker>=0.16->tpot) (2.20.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.20.2->tpot) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.20.2->tpot) (2.7.3)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.23)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.20.2->tpot) (1.11.0)\n",
      "Building wheels for collected packages: stopit\n",
      "  Running setup.py bdist_wheel for stopit ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
      "Successfully built stopit\n",
      "Installing collected packages: joblib, stopit, update-checker, deap, tpot\n",
      "Successfully installed deap-1.3.0 joblib-0.13.2 stopit-1.1.2 tpot-0.10.2 update-checker-0.16\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "GhI7BzgmhWMy",
    "outputId": "ee393443-4fa2-472a-91c9-1cc9adb296fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>price</th>\n",
       "      <th>body</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engV</th>\n",
       "      <th>engType</th>\n",
       "      <th>registration</th>\n",
       "      <th>year</th>\n",
       "      <th>drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>20500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>17800.0</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>16600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   make    price  body  mileage  engV  engType  registration  year  drive\n",
       "0    23  15500.0     0       68   2.5        1             1  2010      1\n",
       "1    50  20500.0     3      173   1.8        1             1  2011      2\n",
       "2    50  35000.0     2      135   5.5        3             1  2008      2\n",
       "3    50  17800.0     5      162   1.8        0             1  2012      0\n",
       "4    55  16600.0     0       83   2.0        3             1  2013      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "df = pd.read_csv('car_regression.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "XED4cuyimEsP",
    "outputId": "194fc9de-ba89-4006-fc78-0f1953187ce0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>price</th>\n",
       "      <th>body</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engV</th>\n",
       "      <th>engType</th>\n",
       "      <th>registration</th>\n",
       "      <th>year</th>\n",
       "      <th>drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.535491</td>\n",
       "      <td>16185.453305</td>\n",
       "      <td>2.302295</td>\n",
       "      <td>141.744202</td>\n",
       "      <td>2.568337</td>\n",
       "      <td>1.650618</td>\n",
       "      <td>0.941613</td>\n",
       "      <td>2006.500883</td>\n",
       "      <td>0.575868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.526251</td>\n",
       "      <td>24449.641512</td>\n",
       "      <td>1.610307</td>\n",
       "      <td>97.464062</td>\n",
       "      <td>5.387238</td>\n",
       "      <td>1.341282</td>\n",
       "      <td>0.234488</td>\n",
       "      <td>6.925907</td>\n",
       "      <td>0.741235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>259.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1959.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>5490.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>9500.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>17145.600000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>547800.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              make          price         body      mileage         engV  \\\n",
       "count  8495.000000    8495.000000  8495.000000  8495.000000  8495.000000   \n",
       "mean     46.535491   16185.453305     2.302295   141.744202     2.568337   \n",
       "std      24.526251   24449.641512     1.610307    97.464062     5.387238   \n",
       "min       0.000000     259.350000     0.000000     0.000000     0.100000   \n",
       "25%      23.000000    5490.000000     1.000000    74.000000     1.600000   \n",
       "50%      50.000000    9500.000000     3.000000   130.000000     2.000000   \n",
       "75%      68.000000   17145.600000     3.000000   197.000000     2.500000   \n",
       "max      82.000000  547800.000000     5.000000   999.000000    99.990000   \n",
       "\n",
       "           engType  registration         year        drive  \n",
       "count  8495.000000   8495.000000  8495.000000  8495.000000  \n",
       "mean      1.650618      0.941613  2006.500883     0.575868  \n",
       "std       1.341282      0.234488     6.925907     0.741235  \n",
       "min       0.000000      0.000000  1959.000000     0.000000  \n",
       "25%       0.000000      1.000000  2004.000000     0.000000  \n",
       "50%       1.000000      1.000000  2008.000000     0.000000  \n",
       "75%       3.000000      1.000000  2011.000000     1.000000  \n",
       "max       3.000000      1.000000  2016.000000     2.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRdeEEbomGQ6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('price', axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, df['price'].values, train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "p5dAYY5VmuEc",
    "outputId": "41208981-b211-489e-ef52-310cfbb66af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBRegressor is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3641727e3e41a2b181de9970d0b08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -140861881.21250254\n",
      "Generation 2 - Current best internal CV score: -121818035.9099746\n",
      "Generation 3 - Current best internal CV score: -105925728.39144745\n",
      "Generation 4 - Current best internal CV score: -105925728.39144745\n",
      "Generation 5 - Current best internal CV score: -99915477.50603494\n",
      "\n",
      "Best pipeline: KNeighborsRegressor(ExtraTreesRegressor(input_matrix, bootstrap=False, max_features=0.8, min_samples_leaf=5, min_samples_split=10, n_estimators=100), n_neighbors=5, p=1, weights=distance)\n",
      "-107624532.36075398\n",
      "CPU times: user 7min 42s, sys: 2min 22s, total: 10min 5s\n",
      "Wall time: 9min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ma_BH3rpqLFA",
    "outputId": "63602cc4-48a2-461a-d922-4ca2ac354f67"
   },
   "outputs": [],
   "source": [
    "y_pred = tpot.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nTSYqr_dqdNb",
    "outputId": "e04e2b8d-f6f2-4c1d-a452-63b36fb7a578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4500.,  5000.,  5800., ..., 23000., 15000., 10700.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107624532.36075398"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aVijM-bCd6Xh"
   },
   "source": [
    "It works - but it looks like we're not quite out of a job yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hYXU2HBrswcX"
   },
   "source": [
    "## So, is AutoML an \"AGI\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ws30-q7PtEWE"
   },
   "source": [
    "**No** - it's a search (grid or possibly using genetic/tree pruning/etc. heuristics) in parameter space, with some clever type inference heuristics and a slick interface.\n",
    "\n",
    "But, it *is* artificial, it *does* give intelligent results, and (like most technology) it *multiplies* productivity. It's not going to \"take our jobs\" - but it does mean that, in some situations, one data scientist will be able to do what formerly took several to achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "glOqJQkA0bxG"
   },
   "source": [
    "## Is Artificial General Intelligence dangerous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZrQq9D3ik6h"
   },
   "source": [
    "![I'm working to bring about a superintelligent AI that will eternally torment everyone who failed to make fun of the Roko's Basilisk people.](https://imgs.xkcd.com/comics/ai_box_experiment.png)\n",
    "\n",
    "There's been much philosophizing, thought experimenting, and even some genuine advocacy and policy considerations about the impact of a \"true\" AGI on human society. Most of these analyses essentially consider the AGI as an unfathomable deity, thinking and moving in ways well beyond human comprehension.\n",
    "\n",
    "Consider the [paperclip maximizer](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer):\n",
    "\n",
    "> Suppose we have an AI whose only goal is to make as many paper clips as possible. The AI will realize quickly that it would be much better if there were no humans because humans might decide to switch it off. Because if humans do so, there would be fewer paper clips. Also, human bodies contain a lot of atoms that could be made into paper clips. The future that the AI would be trying to gear towards would be one in which there were a lot of paper clips but no humans. â€”â€‰Nick Bostrom\n",
    "\n",
    "This is an example of *instrumental convergence* - the idea that, if an AGI were to pursue an unbounded goal (a natural instruction like \"Maximize the health of all humans\") it may push it in extremely unexpected ways (put all humans in vats of goo, to both preserve them and prevent them from disabling it, since its existence is also of value to help humans).\n",
    "\n",
    "Is this a *realistic* concern? Well, maybe eventually - but pretty obviously not an immediate one. There are many more prominent challenges involving tech and society - privacy, economic growth, equality, education - and even *if* AGI existed it's not clear how they would have the means to enact such fantastic plans. Killer robot armies make for good TV, but at some step there's likely a human with an off switch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ayWGQhHu1yRu"
   },
   "source": [
    "## Where is AI going, and where does it leave us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrBqwYoziUSm"
   },
   "source": [
    "![Lambda calculus? More like SHAMda calculus, amirite?](https://imgs.xkcd.com/comics/ai_research.png)\n",
    "\n",
    "On the one hand, we live in a remarkable time. The explosion of technology from WWII to present has brought about countless innovations, greatly increased median life expectancy and GDP, and shows no sign of slowing down.\n",
    "\n",
    "On the other hand, the more things change the more they stay the same. Humans are still Homo sapiens, with the same brains we've had for many millenia. [Dunbar's number](https://en.wikipedia.org/wiki/Dunbar's_number) stymies our attempts to be globally considerate and aware, and at the end of the day it seems like the vast majority of our behavior is as it ever has been - just with shinier toys.\n",
    "\n",
    "So, what will happen? Will technology usher in a utopia, where automation finally relieves us all of burdensome tasks and we are free to explore science, art, and leisure? Or are we doomed to a dystopia, where increased production is also increasingly centralized and the vast majority of humanity becomes a permanent underclass in a postmodern cyberpunk world?\n",
    "\n",
    "Probably neither - both are extreme points along a continuum of possibility. But wherever we do end up, it is all but certain that AI (that is, technology generating insights and signal) will be a key part of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpbzOQKU7Yv2"
   },
   "source": [
    "## And what about A*G*I?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kB8YZxHc7gGm"
   },
   "source": [
    "> \"I think, therefore I am.\" -- RenÃ© Descartes\n",
    "\n",
    "> \"I am a strange loop.\" -- Douglas Hofstadter\n",
    "\n",
    "Artificial General Intelligence is, as discussed, a moving target. Perhaps what we're looking for isn't intelligence, but consciousness - and specifically, consciousness *we* recognize and empathize with. Much like all parents, us humans want to foster something new in our image, and see it succeed in a way we appreciate.\n",
    "\n",
    "It's not clear if technology will ever *really* get there. The structure and approach to artificial intelligence is inherently, well, artificial - some things like neural networks are \"inspired\" by biology, but still very different (far fewer connections, but far faster with more data). Perhaps computers really already *are* intelligent, just not in a way we recognize.\n",
    "\n",
    "And if we ever do succeed at making our virtual progeny, we may find it bittersweet - not because they will inevitably destroy us (though they probably will outlast us), but simply because it will then lead us to wonder what is so special about us in the first place. If we can create an AGI from metal and sand, then are we not just mechanisms of a different sort?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lfZdD_cp1t5"
   },
   "source": [
    "# Assignment\n",
    "\n",
    "Use either [automl-gs](https://github.com/minimaxir/automl-gs) or [TPOT](https://github.com/EpistasisLab/tpot) to solve at least two of your prior assignments, projects, or other past work (any time you fit a classification or regression model). Report the results, and compare/contrast with the results you found when you worked on it using your \"human\" ML approach.\n",
    "\n",
    "Note - these tools promise a lot, but the reality is that you may have to debug a bit and figure out getting your data in a format that it recognizes. Welcome to the cutting edge - at least there's still plenty of work to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Regression with KC Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'date',\n",
       " 'price',\n",
       " 'bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot15']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "X = df.drop(columns={'id', 'date', 'price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17290, 18), (4323, 18), (17290,), (4323,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBRegressor is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6a967225a44da59a3fe2c4fbe7b0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=80, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(RandomForestRegressor(input_matrix, bootstrap=True, max_features=0.9000000000000001, min_samples_leaf=4, min_samples_split=14, n_estimators=100), max_depth=10, min_samples_leaf=5, min_samples_split=7)\n",
      "-21936196278.573162\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTRegressor(generations=1, population_size=10, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Classification W/Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3131cf0bfa47d9a53bc689f00ed9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=20, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.975278706800446\n",
      "\n",
      "Best pipeline: MultinomialNB(Nystroem(input_matrix, gamma=1.0, kernel=poly, n_components=8), alpha=10.0, fit_prior=True)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=1, population_size=10, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "Stretch goals\n",
    "- Apply AutoML to more data, including data you've not analyzed or data you're considering for project work\n",
    "- Try to work with the GPU/TPU options, and see if you can accelerate your AutoML\n",
    "- Check out other competing AutoML systems (see resources or search and share - many are cloud hosted which is why we went with this)\n",
    "- Write a blog post summarizing your experience learning Data Science at Lambda School!\n",
    "\n",
    "Resources\n",
    "- [What to expect from AutoML software](https://epistasislab.github.io/tpot/using/#what-to-expect-from-automl-software)\n",
    "- [TPOT examples](https://epistasislab.github.io/tpot/examples/)\n",
    "- [Google Cloud AutoML](https://cloud.google.com/automl/) - the Google offering in the AutoML space (also has vision, video, NLP, and translation)\n",
    "- [Microsoft AutoML](https://www.microsoft.com/en-us/research/project/automl/)\n",
    "- [AutoML.org](https://www.automl.org)\n",
    "- [Ludwig](https://uber.github.io/ludwig/) - a toolbox for deep learning that doesn't require coding, from Uber\n",
    "- [USENIX Security '18-Q: Why Do Keynote Speakers Keep Suggesting That Improving Security Is Possible?](https://youtu.be/ajGX7odA87k) - a humorous but informative presentation by James Mickens, focused on security but with a consideration of data and machine learning"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_444_AGI_and_The_Future.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
